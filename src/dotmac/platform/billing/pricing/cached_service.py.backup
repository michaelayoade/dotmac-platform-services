"""
Cached pricing engine for high-performance price calculations.

Caches pricing rules and calculation results to minimize database queries
and improve response times for frequent pricing operations.
"""

import structlog
from datetime import datetime, timezone
from decimal import Decimal
from typing import List, Optional

from dotmac.platform.billing.pricing.models import (
    PricingRule,
    PricingRuleCreateRequest,
    PriceCalculationRequest,
    PriceCalculationResult,
)
from dotmac.platform.billing.pricing.service import PricingEngine
from dotmac.platform.billing.cache import (
    BillingCache,
    CacheKey,
    CacheTier,
    get_billing_cache,
    BillingCacheConfig,
)

logger = structlog.get_logger(__name__)


class CachedPricingEngine(PricingEngine):
    """
    Pricing engine with intelligent caching for improved performance.

    Features:
    - Caches pricing rules per tenant/product
    - Caches price calculation results
    - Smart invalidation on rule changes
    - Batch operations optimization
    """

    def __init__(self):
        super().__init__()
        self.cache: BillingCache = get_billing_cache()
        self.config = BillingCacheConfig()

    async def get_pricing_rule(self, rule_id: str, tenant_id: str) -> PricingRule:
        """
        Get pricing rule with caching.

        Cache strategy:
        - TTL: 30 minutes (configurable)
        - Invalidated on rule updates
        """
        cache_key = CacheKey.pricing_rule(rule_id, tenant_id)

        # Try cache first
        cached_rule = await self.cache.get(cache_key)
        if cached_rule:
            logger.debug("Pricing rule retrieved from cache", rule_id=rule_id, tenant_id=tenant_id)
            return PricingRule.model_validate(cached_rule)

        # Load from database
        rule = await super().get_pricing_rule(rule_id, tenant_id)

        # Cache the result
        await self.cache.set(
            cache_key,
            rule.model_dump(),
            ttl=self.config.PRICING_RULE_TTL,
            tags=[f"tenant:{tenant_id}", f"pricing_rule:{rule_id}"],
        )

        return rule

    async def list_pricing_rules(
        self,
        tenant_id: str,
        active_only: bool = True,
        product_id: Optional[str] = None,
        category: Optional[str] = None,
    ) -> List[PricingRule]:
        """
        List pricing rules with caching for common queries.

        Cache strategy:
        - Cache by tenant and product combination
        - Shorter TTL for list operations
        """
        # Generate cache key
        cache_key = CacheKey.pricing_rules(tenant_id, product_id)

        # Add filters to cache key
        if category:
            cache_key += f":{category}"
        if active_only:
            cache_key += ":active"

        # Try cache first
        cached_rules = await self.cache.get(cache_key)
        if cached_rules:
            logger.debug(
                "Pricing rules retrieved from cache", tenant_id=tenant_id, product_id=product_id
            )
            return [PricingRule.model_validate(r) for r in cached_rules]

        # Load from database
        rules = await super().list_pricing_rules(
            tenant_id, active_only=active_only, product_id=product_id, category=category
        )

        # Cache the result
        if rules:
            await self.cache.set(
                cache_key,
                [r.model_dump() for r in rules],
                ttl=self.config.PRICING_RULE_TTL,
                tags=[f"tenant:{tenant_id}", "pricing_rules"],
            )

        return rules

    async def calculate_price(
        self, request: PriceCalculationRequest, tenant_id: str, use_cache: bool = True
    ) -> PriceCalculationResult:
        """
        Calculate price with result caching.

        Cache strategy:
        - Cache calculation results for identical requests
        - Very short TTL (5 minutes) as prices may change frequently
        - Can be disabled for real-time pricing needs
        """
        # Generate cache key for this calculation
        cache_key = CacheKey.price_calculation(
            request.product_id, request.quantity, request.customer_id, tenant_id
        )

        # Try cache if enabled
        if use_cache:
            cached_result = await self.cache.get(cache_key, tier=CacheTier.L1_MEMORY)
            if cached_result:
                logger.debug(
                    "Price calculation retrieved from cache",
                    product_id=request.product_id,
                    quantity=request.quantity,
                    customer_id=request.customer_id,
                )
                return PriceCalculationResult.model_validate(cached_result)

        # Get applicable pricing rules (these will be cached)
        applicable_rules = await self._get_applicable_rules(
            request.product_id, request.quantity, request.customer_segments, tenant_id
        )

        # Perform calculation
        result = await self._calculate_with_rules(request, applicable_rules, tenant_id)

        # Cache the result if enabled
        if use_cache and result:
            await self.cache.set(
                cache_key,
                result.model_dump(),
                ttl=300,  # 5 minutes for price calculations
                tier=CacheTier.L1_MEMORY,  # Keep in memory for fast access
                tags=[
                    f"tenant:{tenant_id}",
                    f"product:{request.product_id}",
                    f"customer:{request.customer_id}",
                ],
            )

        return result

    async def create_pricing_rule(
        self, rule_data: PricingRuleCreateRequest, tenant_id: str
    ) -> PricingRule:
        """
        Create pricing rule and invalidate relevant caches.
        """
        # Create rule
        rule = await super().create_pricing_rule(rule_data, tenant_id)

        # Invalidate pricing rules caches for this tenant
        await self.cache.invalidate_pattern(f"billing:pricing:rules:{tenant_id}:*")

        # Invalidate price calculations that might be affected
        if rule.applies_to_all:
            # Clear all price calculations for this tenant
            await self.cache.invalidate_pattern(f"billing:price:{tenant_id}:*")
        elif rule.applies_to_product_ids:
            # Clear calculations for specific products
            for product_id in rule.applies_to_product_ids:
                await self.cache.invalidate_pattern(f"billing:price:{tenant_id}:{product_id}:*")

        # Cache the new rule
        cache_key = CacheKey.pricing_rule(rule.rule_id, tenant_id)
        await self.cache.set(
            cache_key,
            rule.model_dump(),
            ttl=self.config.PRICING_RULE_TTL,
            tags=[f"tenant:{tenant_id}", f"pricing_rule:{rule.rule_id}"],
        )

        logger.info(
            "Pricing rule created and cache updated", rule_id=rule.rule_id, tenant_id=tenant_id
        )

        return rule

    async def update_pricing_rule(self, rule_id: str, updates: dict, tenant_id: str) -> PricingRule:
        """
        Update pricing rule and refresh caches.
        """
        # Update rule
        rule = await super().update_pricing_rule(rule_id, updates, tenant_id)

        # Clear rule cache
        cache_key = CacheKey.pricing_rule(rule_id, tenant_id)
        await self.cache.delete(cache_key)

        # Invalidate rules list caches
        await self.cache.invalidate_pattern(f"billing:pricing:rules:{tenant_id}:*")

        # Invalidate affected price calculations
        if rule.applies_to_all:
            await self.cache.invalidate_pattern(f"billing:price:{tenant_id}:*")
        elif rule.applies_to_product_ids:
            for product_id in rule.applies_to_product_ids:
                await self.cache.invalidate_pattern(f"billing:price:{tenant_id}:{product_id}:*")

        # Cache updated rule
        await self.cache.set(
            cache_key,
            rule.model_dump(),
            ttl=self.config.PRICING_RULE_TTL,
            tags=[f"tenant:{tenant_id}", f"pricing_rule:{rule_id}"],
        )

        logger.info(
            "Pricing rule updated and cache refreshed", rule_id=rule_id, tenant_id=tenant_id
        )

        return rule

    async def _get_applicable_rules(
        self, product_id: str, quantity: int, customer_segments: List[str], tenant_id: str
    ) -> List[PricingRule]:
        """
        Get applicable rules with caching optimization.

        This method is called frequently, so we cache the filtered
        results for common product/customer combinations.
        """
        # Create a cache key for this specific combination
        segments_hash = CacheKey.generate_hash({"segments": sorted(customer_segments)})
        cache_key = (
            f"billing:pricing:applicable:{tenant_id}:{product_id}:{quantity}:{segments_hash}"
        )

        # Try cache first
        cached_rules = await self.cache.get(cache_key, tier=CacheTier.L1_MEMORY)
        if cached_rules:
            return [PricingRule.model_validate(r) for r in cached_rules]

        # Get all rules for this tenant (cached)
        all_rules = await self.list_pricing_rules(tenant_id, active_only=True)

        # Filter applicable rules
        applicable = []
        for rule in all_rules:
            # Check if rule applies to this product
            if not self._rule_applies_to_product(rule, product_id):
                continue

            # Check quantity requirements
            if rule.min_quantity and quantity < rule.min_quantity:
                continue

            # Check customer segments
            if rule.customer_segments:
                if not any(seg in customer_segments for seg in rule.customer_segments):
                    continue

            # Check time constraints
            now = datetime.now(timezone.utc)
            if rule.starts_at and now < rule.starts_at:
                continue
            if rule.ends_at and now > rule.ends_at:
                continue

            # Check usage limits
            if rule.max_uses and rule.current_uses >= rule.max_uses:
                continue

            applicable.append(rule)

        # Cache the filtered results
        if applicable:
            await self.cache.set(
                cache_key,
                [r.model_dump() for r in applicable],
                ttl=300,  # 5 minutes
                tier=CacheTier.L1_MEMORY,
            )

        return applicable

    def _rule_applies_to_product(self, rule: PricingRule, product_id: str) -> bool:
        """Check if a rule applies to a specific product."""
        if rule.applies_to_all:
            return True

        if rule.applies_to_product_ids and product_id in rule.applies_to_product_ids:
            return True

        # Would need to check product category here if we had that data
        # For now, just check direct product matches

        return False

    async def _calculate_with_rules(
        self, request: PriceCalculationRequest, rules: List[PricingRule], tenant_id: str
    ) -> PriceCalculationResult:
        """
        Perform the actual price calculation with rules.

        This is the core calculation logic that applies discounts
        based on the first matching rule (first-match-wins).
        """
        # Get product details (this would be cached in CachedProductService)
        from dotmac.platform.billing.catalog.cached_service import CachedProductService

        product_service = CachedProductService()
        product = await product_service.get_product(request.product_id, tenant_id)

        # Base calculation
        base_price = product.base_price
        quantity = Decimal(str(request.quantity))
        subtotal = base_price * quantity

        # Apply first matching rule
        discount_amount = Decimal("0")
        applied_rule = None

        for rule in rules:
            if rule.discount_type == "percentage":
                discount_amount = subtotal * (rule.discount_value / 100)
            elif rule.discount_type == "fixed_amount":
                discount_amount = min(rule.discount_value, subtotal)
            elif rule.discount_type == "fixed_price":
                # Fixed price replaces the original price
                new_total = rule.discount_value * quantity
                discount_amount = max(Decimal("0"), subtotal - new_total)

            applied_rule = rule
            break  # First match wins

        # Calculate final price
        final_price = subtotal - discount_amount

        return PriceCalculationResult(
            product_id=request.product_id,
            quantity=request.quantity,
            currency=product.currency,
            base_price=base_price,
            subtotal=subtotal,
            discounts=(
                [
                    {
                        "rule_id": applied_rule.rule_id if applied_rule else None,
                        "rule_name": applied_rule.name if applied_rule else None,
                        "discount_amount": discount_amount,
                    }
                ]
                if applied_rule
                else []
            ),
            total_discount_amount=discount_amount,
            final_price=final_price,
            applied_rules=[applied_rule.rule_id] if applied_rule else [],
            calculation_metadata={
                "customer_segments": request.customer_segments,
                "timestamp": datetime.now(timezone.utc).isoformat(),
            },
        )

    async def warm_pricing_cache(self, tenant_id: str):
        """
        Pre-load frequently used pricing rules into cache.
        """
        logger.info("Warming pricing cache", tenant_id=tenant_id)

        # Load all active pricing rules
        rules = await super().list_pricing_rules(tenant_id, active_only=True)

        cached_count = 0
        for rule in rules:
            cache_key = CacheKey.pricing_rule(rule.rule_id, tenant_id)
            await self.cache.set(
                cache_key,
                rule.model_dump(),
                ttl=self.config.PRICING_RULE_TTL,
                tags=[f"tenant:{tenant_id}", f"pricing_rule:{rule.rule_id}"],
            )
            cached_count += 1

        logger.info("Pricing cache warmed", tenant_id=tenant_id, cached_count=cached_count)

        return cached_count
