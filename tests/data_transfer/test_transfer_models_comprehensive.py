"""
Comprehensive tests for data transfer models.

Tests all Pydantic models and their validation logic including:
- Enum classes and their values
- Request models with field validation
- Response models and serialization
- Custom validators and error cases
"""

from datetime import UTC, datetime
from uuid import uuid4

import pytest
from pydantic import ValidationError

from dotmac.platform.data_transfer.core import (
    CompressionType,
    DataFormat,
    TransferStatus,
)
from dotmac.platform.data_transfer.models import (  # Enums; Request models; Response models
    DataFormatInfo,
    ExportRequest,
    ExportTarget,
    FormatsResponse,
    ImportRequest,
    ImportSource,
    TransferErrorResponse,
    TransferJobListResponse,
    TransferJobRequest,
    TransferJobResponse,
    TransferProgressUpdate,
    TransferStatistics,
    TransferType,
    TransferValidationResult,
    ValidationLevel,
)


class TestEnums:
    """Test enum classes and their values."""

    def test_transfer_type_enum(self):
        """Test TransferType enum values."""
        assert TransferType.IMPORT == "import"
        assert TransferType.EXPORT == "export"
        assert TransferType.SYNC == "sync"
        assert TransferType.MIGRATE == "migrate"

        # Test all values are present
        all_values = list(TransferType)
        assert len(all_values) == 4

    def test_import_source_enum(self):
        """Test ImportSource enum values."""
        assert ImportSource.FILE == "file"
        assert ImportSource.DATABASE == "database"
        assert ImportSource.API == "api"
        assert ImportSource.S3 == "s3"
        assert ImportSource.SFTP == "sftp"
        assert ImportSource.HTTP == "http"

        # Test all values are present
        all_values = list(ImportSource)
        assert len(all_values) == 6

    def test_export_target_enum(self):
        """Test ExportTarget enum values."""
        assert ExportTarget.FILE == "file"
        assert ExportTarget.DATABASE == "database"
        assert ExportTarget.API == "api"
        assert ExportTarget.S3 == "s3"
        assert ExportTarget.SFTP == "sftp"
        assert ExportTarget.EMAIL == "email"

        # Test all values are present
        all_values = list(ExportTarget)
        assert len(all_values) == 6

    def test_validation_level_enum(self):
        """Test ValidationLevel enum values."""
        assert ValidationLevel.NONE == "none"
        assert ValidationLevel.BASIC == "basic"
        assert ValidationLevel.STRICT == "strict"

        # Test all values are present
        all_values = list(ValidationLevel)
        assert len(all_values) == 3


class TestImportRequest:
    """Test ImportRequest model and validation."""

    def test_import_request_valid_basic(self):
        """Test valid ImportRequest creation with minimal data."""
        request = ImportRequest(
            source_type=ImportSource.FILE, source_path="/path/to/file.csv", format=DataFormat.CSV
        )

        assert request.source_type == ImportSource.FILE
        assert request.source_path == "/path/to/file.csv"
        assert request.format == DataFormat.CSV
        assert request.validation_level == ValidationLevel.BASIC  # default
        assert request.batch_size == 1000  # default
        assert request.encoding == "utf-8"  # default
        assert request.skip_errors is False  # default
        assert request.dry_run is False  # default

    def test_import_request_valid_full(self):
        """Test valid ImportRequest with all fields."""
        mapping = {"old_field": "new_field", "source_id": "target_id"}
        options = {"delimiter": ",", "headers": True}

        request = ImportRequest(
            source_type=ImportSource.DATABASE,
            source_path="postgresql://user:pass@host:5432/db",
            format=DataFormat.JSON,
            mapping=mapping,
            options=options,
            validation_level=ValidationLevel.STRICT,
            batch_size=500,
            encoding="utf-16",
            skip_errors=True,
            dry_run=True,
        )

        assert request.source_type == ImportSource.DATABASE
        assert request.source_path == "postgresql://user:pass@host:5432/db"
        assert request.format == DataFormat.JSON
        assert request.mapping == mapping
        assert request.options == options
        assert request.validation_level == ValidationLevel.STRICT
        assert request.batch_size == 500
        assert request.encoding == "utf-16"
        assert request.skip_errors is True
        assert request.dry_run is True

    def test_import_request_source_path_validation_file(self):
        """Test source path validation for file sources."""
        # Valid file path
        request = ImportRequest(
            source_type=ImportSource.FILE, source_path="/valid/path/file.csv", format=DataFormat.CSV
        )
        assert request.source_path == "/valid/path/file.csv"

        # Invalid file path - parent directory traversal
        with pytest.raises(ValidationError, match="Invalid file path"):
            ImportRequest(
                source_type=ImportSource.FILE, source_path="../invalid/path", format=DataFormat.CSV
            )

        # Empty file path (fails min_length validation)
        with pytest.raises(ValidationError, match="String should have at least 1 character"):
            ImportRequest(source_type=ImportSource.FILE, source_path="", format=DataFormat.CSV)

    def test_import_request_source_path_validation_http(self):
        """Test source path validation for HTTP sources."""
        # Valid HTTP URL
        request = ImportRequest(
            source_type=ImportSource.HTTP,
            source_path="https://api.example.com/data",
            format=DataFormat.JSON,
        )
        assert request.source_path == "https://api.example.com/data"

        # Valid HTTP URL (not HTTPS)
        request = ImportRequest(
            source_type=ImportSource.HTTP,
            source_path="http://api.example.com/data",
            format=DataFormat.JSON,
        )
        assert request.source_path == "http://api.example.com/data"

        # Invalid HTTP URL
        with pytest.raises(ValidationError, match="Source must be a valid HTTP"):
            ImportRequest(
                source_type=ImportSource.HTTP,
                source_path="ftp://invalid.com/data",
                format=DataFormat.JSON,
            )

    def test_import_request_source_path_validation_api(self):
        """Test source path validation for API sources."""
        # Valid HTTPS API URL
        request = ImportRequest(
            source_type=ImportSource.API,
            source_path="https://api.example.com/v1/users",
            format=DataFormat.JSON,
        )
        assert request.source_path == "https://api.example.com/v1/users"

        # Invalid API URL
        with pytest.raises(ValidationError, match="Source must be a valid HTTP"):
            ImportRequest(
                source_type=ImportSource.API, source_path="not-a-url", format=DataFormat.JSON
            )

    def test_import_request_source_path_validation_s3(self):
        """Test source path validation for S3 sources."""
        # Valid S3 path
        request = ImportRequest(
            source_type=ImportSource.S3,
            source_path="s3://bucket-name/path/to/file.json",
            format=DataFormat.JSON,
        )
        assert request.source_path == "s3://bucket-name/path/to/file.json"

        # Invalid S3 path
        with pytest.raises(ValidationError, match="S3 paths must start with s3://"):
            ImportRequest(
                source_type=ImportSource.S3,
                source_path="bucket-name/path/to/file.json",
                format=DataFormat.JSON,
            )

    def test_import_request_mapping_validation(self):
        """Test mapping field validation."""
        # Valid mapping
        mapping = {"source_field": "target_field", "id": "user_id"}
        request = ImportRequest(
            source_type=ImportSource.FILE,
            source_path="/path/to/file.csv",
            format=DataFormat.CSV,
            mapping=mapping,
        )
        assert request.mapping == mapping

        # None mapping (should be allowed)
        request = ImportRequest(
            source_type=ImportSource.FILE,
            source_path="/path/to/file.csv",
            format=DataFormat.CSV,
            mapping=None,
        )
        assert request.mapping is None

        # Too many mappings
        large_mapping = {f"field_{i}": f"target_{i}" for i in range(1001)}
        with pytest.raises(ValidationError, match="Maximum 1000 field mappings"):
            ImportRequest(
                source_type=ImportSource.FILE,
                source_path="/path/to/file.csv",
                format=DataFormat.CSV,
                mapping=large_mapping,
            )

        # Invalid mapping value types (fails Pydantic type validation)
        with pytest.raises(ValidationError, match="Input should be a valid string"):
            ImportRequest(
                source_type=ImportSource.FILE,
                source_path="/path/to/file.csv",
                format=DataFormat.CSV,
                mapping={"field": 123},  # integer value
            )

        # Field names too long - source field
        with pytest.raises(ValidationError, match="Field names must not exceed 100 characters"):
            ImportRequest(
                source_type=ImportSource.FILE,
                source_path="/path/to/file.csv",
                format=DataFormat.CSV,
                mapping={"a" * 101: "target_field"},  # 101 character source field
            )

        # Field names too long - target field
        with pytest.raises(ValidationError, match="Field names must not exceed 100 characters"):
            ImportRequest(
                source_type=ImportSource.FILE,
                source_path="/path/to/file.csv",
                format=DataFormat.CSV,
                mapping={"source_field": "a" * 101},  # 101 character target field
            )

    def test_import_request_batch_size_validation(self):
        """Test batch size validation."""
        # Valid batch size
        request = ImportRequest(
            source_type=ImportSource.FILE,
            source_path="/path/to/file.csv",
            format=DataFormat.CSV,
            batch_size=5000,
        )
        assert request.batch_size == 5000

        # Minimum batch size
        request = ImportRequest(
            source_type=ImportSource.FILE,
            source_path="/path/to/file.csv",
            format=DataFormat.CSV,
            batch_size=1,
        )
        assert request.batch_size == 1

        # Maximum batch size
        request = ImportRequest(
            source_type=ImportSource.FILE,
            source_path="/path/to/file.csv",
            format=DataFormat.CSV,
            batch_size=100000,
        )
        assert request.batch_size == 100000

        # Below minimum
        with pytest.raises(ValidationError):
            ImportRequest(
                source_type=ImportSource.FILE,
                source_path="/path/to/file.csv",
                format=DataFormat.CSV,
                batch_size=0,
            )

        # Above maximum
        with pytest.raises(ValidationError):
            ImportRequest(
                source_type=ImportSource.FILE,
                source_path="/path/to/file.csv",
                format=DataFormat.CSV,
                batch_size=100001,
            )

    def test_import_request_required_fields(self):
        """Test required field validation."""
        # Missing source_type
        with pytest.raises(ValidationError):
            ImportRequest(source_path="/path/to/file.csv", format=DataFormat.CSV)

        # Missing source_path
        with pytest.raises(ValidationError):
            ImportRequest(source_type=ImportSource.FILE, format=DataFormat.CSV)

        # Missing format
        with pytest.raises(ValidationError):
            ImportRequest(source_type=ImportSource.FILE, source_path="/path/to/file.csv")

    def test_import_request_string_strip_whitespace(self):
        """Test that string fields are stripped of whitespace."""
        request = ImportRequest(
            source_type=ImportSource.FILE,
            source_path="  /path/to/file.csv  ",
            format=DataFormat.CSV,
            encoding="  utf-8  ",
        )

        assert request.source_path == "/path/to/file.csv"
        assert request.encoding == "utf-8"


class TestExportRequest:
    """Test ExportRequest model and validation."""

    def test_export_request_valid_basic(self):
        """Test valid ExportRequest creation with minimal data."""
        request = ExportRequest(
            target_type=ExportTarget.FILE, target_path="/output/data.csv", format=DataFormat.CSV
        )

        assert request.target_type == ExportTarget.FILE
        assert request.target_path == "/output/data.csv"
        assert request.format == DataFormat.CSV
        # Test defaults would be checked here if they exist

    def test_export_request_valid_full(self):
        """Test valid ExportRequest with all fields."""
        filters = {"status": "active", "created_after": "2023-01-01"}
        options = {"delimiter": "|", "include_headers": False}

        request = ExportRequest(
            target_type=ExportTarget.S3,
            target_path="s3://my-bucket/exports/data.json",
            format=DataFormat.JSON,
            compression=CompressionType.GZIP,
            filters=filters,
            options=options,
            batch_size=2000,
        )

        assert request.target_type == ExportTarget.S3
        assert request.target_path == "s3://my-bucket/exports/data.json"
        assert request.format == DataFormat.JSON
        assert request.compression == CompressionType.GZIP
        assert request.filters == filters
        assert request.options == options
        assert request.batch_size == 2000

    def test_export_request_target_path_validation_email(self):
        """Test target path validation for email targets."""
        # Valid email
        request = ExportRequest(
            target_type=ExportTarget.EMAIL, target_path="user@example.com", format=DataFormat.JSON
        )
        assert request.target_path == "user@example.com"

        # Invalid email - no @
        with pytest.raises(ValidationError, match="Invalid email address"):
            ExportRequest(
                target_type=ExportTarget.EMAIL, target_path="invalid-email", format=DataFormat.JSON
            )

        # Invalid email - too short
        with pytest.raises(ValidationError, match="Invalid email address"):
            ExportRequest(target_type=ExportTarget.EMAIL, target_path="a@b", format=DataFormat.JSON)

    def test_export_request_target_path_validation_file(self):
        """Test target path validation for file targets."""
        # Valid file path
        request = ExportRequest(
            target_type=ExportTarget.FILE,
            target_path="/valid/path/output.json",
            format=DataFormat.JSON,
        )
        assert request.target_path == "/valid/path/output.json"

        # Invalid file path - parent directory traversal
        with pytest.raises(ValidationError, match="Invalid file path"):
            ExportRequest(
                target_type=ExportTarget.FILE, target_path="../invalid/path", format=DataFormat.JSON
            )

    def test_export_request_target_path_validation_s3(self):
        """Test target path validation for S3 targets."""
        # Valid S3 path
        request = ExportRequest(
            target_type=ExportTarget.S3,
            target_path="s3://my-bucket/output/data.json",
            format=DataFormat.JSON,
        )
        assert request.target_path == "s3://my-bucket/output/data.json"

        # Invalid S3 path
        with pytest.raises(ValidationError, match="S3 paths must start with s3://"):
            ExportRequest(
                target_type=ExportTarget.S3,
                target_path="my-bucket/output/data.json",
                format=DataFormat.JSON,
            )

    def test_export_request_fields_validation(self):
        """Test fields validation with duplicate removal."""
        # Fields with duplicates - should remove duplicates while preserving order
        fields_with_duplicates = ["field1", "field2", "field1", "field3", "field2", "field4"]
        expected_unique = ["field1", "field2", "field3", "field4"]

        request = ExportRequest(
            target_type=ExportTarget.FILE,
            target_path="/output/data.csv",
            format=DataFormat.CSV,
            fields=fields_with_duplicates,
        )

        assert request.fields == expected_unique

        # None fields - should remain None
        request = ExportRequest(
            target_type=ExportTarget.FILE,
            target_path="/output/data.csv",
            format=DataFormat.CSV,
            fields=None,
        )

        assert request.fields is None


class TestTransferJobResponse:
    """Test TransferJobResponse model."""

    def test_transfer_job_response_creation(self):
        """Test TransferJobResponse creation."""
        job_id = uuid4()
        created_at = datetime.now(UTC)
        metadata = {"source": "test", "user": "admin"}

        response = TransferJobResponse(
            job_id=job_id,
            name="Test Import Job",
            type=TransferType.IMPORT,
            status=TransferStatus.PENDING,
            progress=0.0,
            created_at=created_at,
            records_processed=0,
            records_failed=0,
            records_total=None,
            metadata=metadata,
        )

        assert response.job_id == job_id
        assert response.name == "Test Import Job"
        assert response.type == TransferType.IMPORT
        assert response.status == TransferStatus.PENDING
        assert response.progress == 0.0
        assert response.created_at == created_at
        assert response.records_processed == 0
        assert response.records_failed == 0
        assert response.records_total is None
        assert response.metadata == metadata

    def test_transfer_job_response_completed(self):
        """Test TransferJobResponse for completed job."""
        job_id = uuid4()
        created_at = datetime.now(UTC)
        started_at = created_at
        completed_at = datetime.now(UTC)

        response = TransferJobResponse(
            job_id=job_id,
            name="Completed Export",
            type=TransferType.EXPORT,
            status=TransferStatus.COMPLETED,
            progress=100.0,
            created_at=created_at,
            started_at=started_at,
            completed_at=completed_at,
            records_processed=1000,
            records_failed=5,
            records_total=1000,
        )

        assert response.status == TransferStatus.COMPLETED
        assert response.progress == 100.0
        assert response.started_at == started_at
        assert response.completed_at == completed_at
        assert response.records_processed == 1000
        assert response.records_failed == 5
        assert response.records_total == 1000

    def test_transfer_job_response_duration_property(self):
        """Test duration property calculation."""
        job_id = uuid4()
        created_at = datetime.now(UTC)
        started_at = created_at
        completed_at = datetime.now(UTC)

        # Job with both start and completion times
        response = TransferJobResponse(
            job_id=job_id,
            name="Test Job",
            type=TransferType.IMPORT,
            status=TransferStatus.COMPLETED,
            progress=100.0,
            created_at=created_at,
            started_at=started_at,
            completed_at=completed_at,
            records_processed=1000,
            records_failed=0,
            records_total=1000,
        )

        # Duration should be calculated
        duration = response.duration
        assert duration is not None
        assert isinstance(duration, float)
        assert duration >= 0

        # Job without completion time
        response_incomplete = TransferJobResponse(
            job_id=job_id,
            name="Incomplete Job",
            type=TransferType.IMPORT,
            status=TransferStatus.RUNNING,
            progress=50.0,
            created_at=created_at,
            started_at=started_at,
            records_processed=500,
            records_failed=0,
        )

        assert response_incomplete.duration is None

        # Job without start time
        response_not_started = TransferJobResponse(
            job_id=job_id,
            name="Not Started Job",
            type=TransferType.IMPORT,
            status=TransferStatus.PENDING,
            progress=0.0,
            created_at=created_at,
            records_processed=0,
            records_failed=0,
        )

        assert response_not_started.duration is None

    def test_transfer_job_response_success_rate_property(self):
        """Test success_rate property calculation."""
        job_id = uuid4()
        created_at = datetime.now(UTC)

        # Job with some failures
        response_with_failures = TransferJobResponse(
            job_id=job_id,
            name="Job with Failures",
            type=TransferType.IMPORT,
            status=TransferStatus.COMPLETED,
            progress=100.0,
            created_at=created_at,
            records_processed=80,
            records_failed=20,
            records_total=100,
        )

        assert response_with_failures.success_rate == 80.0

        # Job with no failures
        response_perfect = TransferJobResponse(
            job_id=job_id,
            name="Perfect Job",
            type=TransferType.IMPORT,
            status=TransferStatus.COMPLETED,
            progress=100.0,
            created_at=created_at,
            records_processed=100,
            records_failed=0,
            records_total=100,
        )

        assert response_perfect.success_rate == 100.0

        # Job with no records processed (edge case)
        response_no_records = TransferJobResponse(
            job_id=job_id,
            name="No Records Job",
            type=TransferType.IMPORT,
            status=TransferStatus.COMPLETED,
            progress=100.0,
            created_at=created_at,
            records_processed=0,
            records_failed=0,
            records_total=0,
        )

        assert response_no_records.success_rate == 100.0


class TestTransferJobListResponse:
    """Test TransferJobListResponse model."""

    def test_transfer_job_list_response(self):
        """Test TransferJobListResponse creation."""
        job1 = TransferJobResponse(
            job_id=uuid4(),
            name="Job 1",
            type=TransferType.IMPORT,
            status=TransferStatus.COMPLETED,
            progress=100.0,
            created_at=datetime.now(UTC),
            records_processed=500,
            records_failed=0,
            records_total=500,
        )

        job2 = TransferJobResponse(
            job_id=uuid4(),
            name="Job 2",
            type=TransferType.EXPORT,
            status=TransferStatus.RUNNING,
            progress=45.5,
            created_at=datetime.now(UTC),
            records_processed=455,
            records_failed=5,
            records_total=1000,
        )

        response = TransferJobListResponse(
            jobs=[job1, job2], total=2, page=1, page_size=10, has_more=False
        )

        assert len(response.jobs) == 2
        assert response.jobs[0] == job1
        assert response.jobs[1] == job2
        assert response.total == 2
        assert response.page == 1
        assert response.page_size == 10
        assert response.has_more is False


class TestDataFormatInfo:
    """Test DataFormatInfo model."""

    def test_data_format_info_creation(self):
        """Test DataFormatInfo creation."""
        options = {
            "delimiter": "Delimiter character",
            "encoding": "File encoding",
            "headers": "Include headers",
        }

        info = DataFormatInfo(
            format=DataFormat.CSV,
            name="Comma-Separated Values",
            file_extensions=[".csv", ".tsv"],
            mime_types=["text/csv", "application/csv"],
            supports_compression=True,
            supports_streaming=True,
            options=options,
        )

        assert info.format == DataFormat.CSV
        assert info.name == "Comma-Separated Values"
        assert info.file_extensions == [".csv", ".tsv"]
        assert info.mime_types == ["text/csv", "application/csv"]
        assert info.supports_compression is True
        assert info.supports_streaming is True
        assert info.options == options


class TestFormatsResponse:
    """Test FormatsResponse model."""

    def test_formats_response_creation(self):
        """Test FormatsResponse creation."""
        csv_info = DataFormatInfo(
            format=DataFormat.CSV,
            name="CSV",
            file_extensions=[".csv"],
            mime_types=["text/csv"],
            supports_compression=True,
            supports_streaming=True,
        )

        json_info = DataFormatInfo(
            format=DataFormat.JSON,
            name="JSON",
            file_extensions=[".json"],
            mime_types=["application/json"],
            supports_compression=True,
            supports_streaming=False,
        )

        response = FormatsResponse(
            import_formats=[csv_info, json_info],
            export_formats=[csv_info],
            compression_types=["none", "gzip", "zip"],
        )

        assert len(response.import_formats) == 2
        assert len(response.export_formats) == 1
        assert response.compression_types == ["none", "gzip", "zip"]


class TestTransferErrorResponse:
    """Test TransferErrorResponse model."""

    def test_transfer_error_response_creation(self):
        """Test TransferErrorResponse creation."""
        job_id = uuid4()
        timestamp = datetime.now(UTC)
        error = TransferErrorResponse(
            error="VALIDATION_FAILED",
            message="Data validation failed",
            details={"field": "email", "reason": "Invalid format"},
            job_id=job_id,
            timestamp=timestamp,
            suggestions=["Check email format", "Verify data source"],
        )

        assert error.error == "VALIDATION_FAILED"
        assert error.message == "Data validation failed"
        assert error.details == {"field": "email", "reason": "Invalid format"}
        assert error.job_id == job_id
        assert error.timestamp == timestamp
        assert error.suggestions == ["Check email format", "Verify data source"]

    def test_transfer_error_response_minimal(self):
        """Test TransferErrorResponse with minimal required fields."""
        timestamp = datetime.now(UTC)
        error = TransferErrorResponse(
            error="NETWORK_ERROR",
            message="Failed to connect to remote server",
            timestamp=timestamp,  # Provide timestamp manually due to bug in models.py
        )

        assert error.error == "NETWORK_ERROR"
        assert error.message == "Failed to connect to remote server"
        assert error.details is None
        assert error.job_id is None
        assert error.suggestions is None
        assert error.timestamp == timestamp


class TestTransferValidationResult:
    """Test TransferValidationResult model."""

    def test_transfer_validation_result_valid(self):
        """Test TransferValidationResult for valid data."""
        sample_data = [
            {"id": 1, "name": "John", "email": "john@example.com"},
            {"id": 2, "name": "Jane", "email": "jane@example.com"},
        ]
        schema = {"id": "integer", "name": "string", "email": "string"}

        result = TransferValidationResult(
            is_valid=True,
            errors=[],
            warnings=[],
            record_count=1000,
            sample_data=sample_data,
            json_schema=schema,
        )

        assert result.is_valid is True
        assert result.errors == []
        assert result.warnings == []
        assert result.record_count == 1000
        assert result.sample_data == sample_data
        assert result.json_schema == schema

    def test_transfer_validation_result_with_errors(self):
        """Test TransferValidationResult with errors."""
        errors = ["Row 5: Invalid email format", "Row 10: Age must be positive"]
        warnings = ["Row 3: Missing country code"]

        result = TransferValidationResult(
            is_valid=False, errors=errors, warnings=warnings, record_count=100
        )

        assert result.is_valid is False
        assert result.errors == errors
        assert result.warnings == warnings
        assert result.record_count == 100
        assert result.sample_data is None
        assert result.json_schema is None


class TestTransferJobRequest:
    """Test TransferJobRequest model."""

    def test_transfer_job_request_basic(self):
        """Test TransferJobRequest with minimal data."""
        request = TransferJobRequest(name="Daily Import Job")

        assert request.name == "Daily Import Job"
        assert request.description is None
        assert request.schedule is None
        assert request.notification_email is None
        assert request.retry_on_failure is True  # default
        assert request.max_retries == 3  # default

    def test_transfer_job_request_full(self):
        """Test TransferJobRequest with all fields."""
        request = TransferJobRequest(
            name="Nightly Data Export",
            description="Export customer data nightly",
            schedule="0 2 * * *",  # Daily at 2 AM
            notification_email="admin@example.com",
            retry_on_failure=False,
            max_retries=5,
        )

        assert request.name == "Nightly Data Export"
        assert request.description == "Export customer data nightly"
        assert request.schedule == "0 2 * * *"
        assert request.notification_email == "admin@example.com"
        assert request.retry_on_failure is False
        assert request.max_retries == 5

    def test_transfer_job_request_name_validation(self):
        """Test job name validation."""
        # Valid name
        request = TransferJobRequest(name="Valid Job Name")
        assert request.name == "Valid Job Name"

        # Empty name should fail
        with pytest.raises(ValidationError):
            TransferJobRequest(name="")

        # Name too long should fail
        long_name = "a" * 256
        with pytest.raises(ValidationError):
            TransferJobRequest(name=long_name)

        # Maximum length name should pass
        max_name = "a" * 255
        request = TransferJobRequest(name=max_name)
        assert len(request.name) == 255

    def test_transfer_job_request_max_retries_validation(self):
        """Test max_retries validation."""
        # Valid retry counts
        for retries in [0, 5, 10]:
            request = TransferJobRequest(name="Test Job", max_retries=retries)
            assert request.max_retries == retries

        # Below minimum should fail
        with pytest.raises(ValidationError):
            TransferJobRequest(name="Test Job", max_retries=-1)

        # Above maximum should fail
        with pytest.raises(ValidationError):
            TransferJobRequest(name="Test Job", max_retries=11)

    def test_transfer_job_request_description_validation(self):
        """Test description length validation."""
        # Valid description
        request = TransferJobRequest(name="Test Job", description="This is a valid description")
        assert request.description == "This is a valid description"

        # Maximum length description
        max_desc = "a" * 1000
        request = TransferJobRequest(name="Test Job", description=max_desc)
        assert len(request.description) == 1000

        # Description too long should fail
        long_desc = "a" * 1001
        with pytest.raises(ValidationError):
            TransferJobRequest(name="Test Job", description=long_desc)


class TestTransferProgressUpdate:
    """Test TransferProgressUpdate model."""

    def test_transfer_progress_update_basic(self):
        """Test TransferProgressUpdate creation."""
        job_id = uuid4()
        update = TransferProgressUpdate(
            job_id=job_id,
            status=TransferStatus.RUNNING,
            progress=45.5,
            current_batch=5,
            records_processed=4500,
            records_failed=25,
        )

        assert update.job_id == job_id
        assert update.status == TransferStatus.RUNNING
        assert update.progress == 45.5
        assert update.current_batch == 5
        assert update.total_batches is None
        assert update.records_processed == 4500
        assert update.records_failed == 25
        assert update.current_file is None
        assert update.message is None
        assert update.estimated_completion is None

    def test_transfer_progress_update_full(self):
        """Test TransferProgressUpdate with all fields."""
        job_id = uuid4()
        estimated_completion = datetime.now(UTC)

        update = TransferProgressUpdate(
            job_id=job_id,
            status=TransferStatus.RUNNING,
            progress=75.0,
            current_batch=8,
            total_batches=10,
            records_processed=7500,
            records_failed=50,
            current_file="batch_008.csv",
            message="Processing batch 8 of 10",
            estimated_completion=estimated_completion,
        )

        assert update.job_id == job_id
        assert update.status == TransferStatus.RUNNING
        assert update.progress == 75.0
        assert update.current_batch == 8
        assert update.total_batches == 10
        assert update.records_processed == 7500
        assert update.records_failed == 50
        assert update.current_file == "batch_008.csv"
        assert update.message == "Processing batch 8 of 10"
        assert update.estimated_completion == estimated_completion

    def test_transfer_progress_update_completed(self):
        """Test TransferProgressUpdate for completed job."""
        job_id = uuid4()
        update = TransferProgressUpdate(
            job_id=job_id,
            status=TransferStatus.COMPLETED,
            progress=100.0,
            current_batch=10,
            total_batches=10,
            records_processed=10000,
            records_failed=0,
            message="Job completed successfully",
        )

        assert update.status == TransferStatus.COMPLETED
        assert update.progress == 100.0
        assert update.current_batch == 10
        assert update.total_batches == 10
        assert update.records_processed == 10000
        assert update.records_failed == 0
        assert update.message == "Job completed successfully"


class TestTransferStatistics:
    """Test TransferStatistics model."""

    def test_transfer_statistics_creation(self):
        """Test TransferStatistics creation."""
        stats = TransferStatistics(
            total_jobs=100,
            completed_jobs=85,
            failed_jobs=10,
            in_progress_jobs=5,
            total_records_processed=1000000,
            total_bytes_transferred=1073741824,
            average_job_duration=120.5,
            success_rate=85.0,
            busiest_hour=14,
            most_used_format="csv",
        )

        assert stats.total_jobs == 100
        assert stats.completed_jobs == 85
        assert stats.failed_jobs == 10
        assert stats.in_progress_jobs == 5
        assert stats.total_records_processed == 1000000
        assert stats.total_bytes_transferred == 1073741824
        assert stats.average_job_duration == 120.5
        assert stats.success_rate == 85.0
        assert stats.busiest_hour == 14
        assert stats.most_used_format == "csv"


class TestModelSerialization:
    """Test model serialization and deserialization."""

    def test_import_request_serialization(self):
        """Test ImportRequest serialization/deserialization."""
        original = ImportRequest(
            source_type=ImportSource.FILE,
            source_path="/path/to/file.csv",
            format=DataFormat.CSV,
            mapping={"old": "new"},
            batch_size=500,
        )

        # Serialize to dict
        data = original.model_dump()
        assert isinstance(data, dict)
        assert data["source_type"] == "file"
        assert data["source_path"] == "/path/to/file.csv"
        assert data["format"] == "csv"
        assert data["mapping"] == {"old": "new"}
        assert data["batch_size"] == 500

        # Deserialize from dict
        reconstructed = ImportRequest.model_validate(data)
        assert reconstructed.source_type == original.source_type
        assert reconstructed.source_path == original.source_path
        assert reconstructed.format == original.format
        assert reconstructed.mapping == original.mapping
        assert reconstructed.batch_size == original.batch_size

    def test_transfer_job_response_serialization(self):
        """Test TransferJobResponse serialization."""
        job_id = uuid4()
        created_at = datetime.now(UTC)

        original = TransferJobResponse(
            job_id=job_id,
            name="Test Job",
            type=TransferType.IMPORT,
            status=TransferStatus.RUNNING,
            progress=50.0,
            created_at=created_at,
            records_processed=500,
            records_failed=5,
            records_total=1000,
        )

        # Serialize to dict
        data = original.model_dump()
        assert isinstance(data, dict)
        assert data["job_id"] == job_id  # UUID objects are preserved in model_dump by default
        assert data["name"] == "Test Job"
        assert data["type"] == "import"
        assert data["status"] == "running"
        assert data["progress"] == 50.0

        # Deserialize from dict
        reconstructed = TransferJobResponse.model_validate(data)
        assert reconstructed.job_id == original.job_id
        assert reconstructed.name == original.name
        assert reconstructed.type == original.type
        assert reconstructed.status == original.status
        assert reconstructed.progress == original.progress


class TestModelEdgeCases:
    """Test edge cases and error conditions."""

    def test_import_request_with_invalid_enum_values(self):
        """Test ImportRequest with invalid enum values."""
        # Invalid source_type
        with pytest.raises(ValidationError):
            ImportRequest(
                source_type="invalid_source",  # Not a valid ImportSource
                source_path="/path/to/file.csv",
                format=DataFormat.CSV,
            )

        # Invalid format
        with pytest.raises(ValidationError):
            ImportRequest(
                source_type=ImportSource.FILE,
                source_path="/path/to/file.csv",
                format="invalid_format",  # Not a valid DataFormat
            )

        # Invalid validation_level
        with pytest.raises(ValidationError):
            ImportRequest(
                source_type=ImportSource.FILE,
                source_path="/path/to/file.csv",
                format=DataFormat.CSV,
                validation_level="invalid_level",  # Not a valid ValidationLevel
            )

    def test_source_path_length_validation(self):
        """Test source path length limits."""
        # Maximum length path (1000 characters)
        long_path = "a" * 1000
        request = ImportRequest(
            source_type=ImportSource.FILE, source_path=long_path, format=DataFormat.CSV
        )
        assert len(request.source_path) == 1000

        # Path too long (1001 characters)
        too_long_path = "a" * 1001
        with pytest.raises(ValidationError):
            ImportRequest(
                source_type=ImportSource.FILE, source_path=too_long_path, format=DataFormat.CSV
            )

        # Empty path
        with pytest.raises(ValidationError):
            ImportRequest(source_type=ImportSource.FILE, source_path="", format=DataFormat.CSV)

    def test_options_field_flexibility(self):
        """Test that options field accepts various data types."""
        # Dictionary options
        request = ImportRequest(
            source_type=ImportSource.FILE,
            source_path="/path/to/file.csv",
            format=DataFormat.CSV,
            options={"delimiter": ",", "skip_rows": 1, "use_headers": True},
        )
        assert request.options["delimiter"] == ","
        assert request.options["skip_rows"] == 1
        assert request.options["use_headers"] is True

        # None options
        request = ImportRequest(
            source_type=ImportSource.FILE,
            source_path="/path/to/file.csv",
            format=DataFormat.CSV,
            options=None,
        )
        assert request.options is None
